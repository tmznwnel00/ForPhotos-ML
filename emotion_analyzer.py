import cv2
import numpy as np
import matplotlib.pyplot as plt
from deepface import DeepFace
import os
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

class EmotionAnalyzer:
    def __init__(self):
        """
        ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™”
        """
        self.emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']
        self.emotion_korean = {
            'angry': 'í™”ë‚¨',
            'disgust': 'ì—­ê²¨ì›€',
            'fear': 'ë‘ë ¤ì›€',
            'happy': 'í–‰ë³µ',
            'sad': 'ìŠ¬í””',
            'surprise': 'ë†€ëŒ',
            'neutral': 'ë¬´í‘œì •'
        }
    
    def analyze_emotion(self, image_path):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ (bounding box í¬í•¨)
        """
        try:
            # DeepFaceë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„
            result = DeepFace.analyze(image_path, 
                                    actions=['emotion'],
                                    enforce_detection=False)
            # ê²°ê³¼ ì²˜ë¦¬
            if isinstance(result, list):
                # ì—¬ëŸ¬ ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°
                emotions = []
                for face_result in result:
                    emotion = face_result['dominant_emotion']
                    confidence = face_result['emotion'][emotion]
                    # bounding box ì •ë³´ ì¶”ê°€ (x, y, w, h)
                    region = face_result.get('region', None)
                    if region:
                        x, y, w, h = region['x'], region['y'], region['w'], region['h']
                    else:
                        x, y, w, h = None, None, None, None
                    emotions.append({
                        'emotion': emotion,
                        'confidence': confidence,
                        'box': (x, y, w, h)
                    })
                return emotions
            else:
                # ë‹¨ì¼ ì–¼êµ´ì´ ê°ì§€ëœ ê²½ìš°
                emotion = result['dominant_emotion']
                confidence = result['emotion'][emotion]
                region = result.get('region', None)
                if region:
                    x, y, w, h = region['x'], region['y'], region['w'], region['h']
                else:
                    x, y, w, h = None, None, None, None
                return [{
                    'emotion': emotion,
                    'confidence': confidence,
                    'box': (x, y, w, h)
                }]
        except Exception as e:
            print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
    
    def analyze_multiple_images(self, image_paths):
        """
        ì—¬ëŸ¬ ì´ë¯¸ì§€ì—ì„œ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.
        
        Args:
            image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê° ì´ë¯¸ì§€ë³„ ê°ì • ë¶„ì„ ê²°ê³¼
        """
        results = {}
        
        for image_path in image_paths:
            if os.path.exists(image_path):
                print(f"ë¶„ì„ ì¤‘: {image_path}")
                emotions = self.analyze_emotion(image_path)
                results[image_path] = emotions
            else:
                print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                results[image_path] = []
        
        return results
    
    def visualize_results(self, results):
        """
        ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        Args:
            results: ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not results:
            print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê²°ê³¼ ê°œìˆ˜ì— ë”°ë¼ ì„œë¸Œí”Œë¡¯ í¬ê¸° ê²°ì •
        n_images = len(results)
        # ê° ì´ë¯¸ì§€ë§ˆë‹¤ 2ê°œì˜ ì„œë¸Œí”Œë¡¯ (ì´ë¯¸ì§€ + ê°ì • ë¦¬ìŠ¤íŠ¸)
        cols = 2  # í•­ìƒ 2ì—´ (ì´ë¯¸ì§€ + ê°ì • ë¦¬ìŠ¤íŠ¸)
        rows = n_images
        
        # ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ë” í¬ê²Œ ì„¤ì •
        fig, axes = plt.subplots(rows, cols, figsize=(20, 8*rows))
        if n_images == 1:
            axes = axes.reshape(1, -1)
        
        # ì„œë¸Œí”Œë¡¯ ê°„ê²© ì¡°ì •
        plt.subplots_adjust(wspace=0.1)  # ì„œë¸Œí”Œë¡¯ ê°„ ê°€ë¡œ ê°„ê²© ì¤„ì´ê¸°
        
        for idx, (image_path, emotions) in enumerate(results.items()):
            if idx >= rows:
                break
            
            # ì™¼ìª½ ì„œë¸Œí”Œë¡¯: ì´ë¯¸ì§€ í‘œì‹œ
            img = cv2.imread(image_path)
            if img is not None:
                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                # ì–¼êµ´ ë²ˆí˜¸ì™€ ê°ì •ëª… í‘œì‹œ
                if emotions:
                    for i, emotion_data in enumerate(emotions):
                        box = emotion_data.get('box', (None, None, None, None))
                        x, y, w, h = box
                        if None not in box:
                            # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
                            cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)
                            # ë²ˆí˜¸+ê°ì •ëª… ë¼ë²¨ (ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì— í‘œì‹œ)
                            label = f"{i+1}: {emotion_data['emotion']}"
                            # ë¼ë²¨ì„ ì–¼êµ´ ì‚¬ê°í˜• ìœ„ìª½ì— ë°°ì¹˜
                            label_x = x
                            label_y = y - 10  # ì‚¬ê°í˜• ìœ„ìª½ì—ì„œ 10í”½ì…€ ë–¨ì–´ì§„ ìœ„ì¹˜
                            cv2.putText(img_rgb, label, (label_x, label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
                
                axes[idx, 0].imshow(img_rgb)
                axes[idx, 0].axis('off')
            else:
                axes[idx, 0].text(0.5, 0.5, f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n{os.path.basename(image_path)}", 
                                 ha='center', va='center', transform=axes[idx, 0].transAxes)
                axes[idx, 0].axis('off')
            
            # ì˜¤ë¥¸ìª½ ì„œë¸Œí”Œë¡¯: ê°ì • ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
            axes[idx, 1].axis('off')
            if emotions:
                # ê°ì • ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
                emotion_text = f"result :\n\n"
                for i, emotion_data in enumerate(emotions):
                    emotion_text += f"face {i+1}: {emotion_data['emotion']} ({emotion_data['confidence']:.1f}%)\n"
                
                axes[idx, 1].text(0.1, 0.9, emotion_text, transform=axes[idx, 1].transAxes, 
                                 fontsize=12, va='top', 
                                 bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
            else:
                axes[idx, 1].text(0.5, 0.5, "ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 
                                 ha='center', va='center', transform=axes[idx, 1].transAxes,
                                 fontsize=12, bbox=dict(boxstyle='round,pad=0.5', facecolor='lightcoral', alpha=0.8))
        
        plt.tight_layout()
        plt.show()
    
    def print_summary(self, results):
        """
        ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
        
        Args:
            results: ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("\n" + "="*50)
        print("ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("="*50)
        
        total_faces = 0
        emotion_counts = {emotion: 0 for emotion in self.emotions}
        
        for image_path, emotions in results.items():
            print(f"\nğŸ“¸ {os.path.basename(image_path)}:")
            
            if emotions:
                for i, emotion_data in enumerate(emotions):
                    emotion = emotion_data['emotion']
                    confidence = emotion_data['confidence']
                    
                    print(f"  ì–¼êµ´ {i+1}: {emotion} ({confidence:.1f}%)")
                    emotion_counts[emotion] += 1
                    total_faces += 1
            else:
                print("  âŒ ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì „ì²´ í†µê³„
        print(f"\nğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  ì´ ê°ì§€ëœ ì–¼êµ´ ìˆ˜: {total_faces}")
        
        if total_faces > 0:
            print("  ê°ì • ë¶„í¬:")
            for emotion in self.emotions:
                if emotion_counts[emotion] > 0:
                    percentage = (emotion_counts[emotion] / total_faces) * 100
                    print(f"    {emotion}: {emotion_counts[emotion]}ëª… ({percentage:.1f}%)")

def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - ì˜ˆì œ ì‹¤í–‰
    """
    analyzer = EmotionAnalyzer()
    
    # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ íŒŒì¼ë“¤ (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”)
    test_images = [
        'input.jpg',  # ì‹¤ì œ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½
        # 'person1.jpg',
        # 'person2.jpg',
        # 'group_photo.jpg'
    ]
    
    # ì¡´ì¬í•˜ëŠ” íŒŒì¼ë§Œ í•„í„°ë§
    existing_images = [img for img in test_images if os.path.exists(img)]
    
    if not existing_images:
        print("ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
        sample_image = np.random.randint(0, 255, (300, 400, 3), dtype=np.uint8)
        cv2.imwrite('sample_face.jpg', sample_image)
        existing_images = ['sample_face.jpg']
    
    print(f"ë¶„ì„í•  ì´ë¯¸ì§€: {existing_images}")
    
    # ê°ì • ë¶„ì„ ì‹¤í–‰
    results = analyzer.analyze_multiple_images(existing_images)
    
    # ê²°ê³¼ ì‹œê°í™”
    analyzer.visualize_results(results)
    
    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    analyzer.print_summary(results)

if __name__ == "__main__":
    main() 