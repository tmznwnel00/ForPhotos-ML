import cv2
import numpy as np
import matplotlib
matplotlib.use('Agg')  # ì„œë²„/í„°ë¯¸ë„ í™˜ê²½ì—ì„œ ì´ë¯¸ì§€ ì €ì¥ìš©
import matplotlib.pyplot as plt
from deepface import DeepFace
import os
from PIL import Image
import warnings
warnings.filterwarnings('ignore')


# === ê°ì •ë³„ ì´ëª¨ì§€ ê²½ë¡œ ë§¤í•‘ (íˆ¬ëª… ë°°ê²½ PNG ê¶Œì¥) ===
EMOJI_MAP = {
    'happy':    'emojis/happy.png',
    'sad':      'emojis/sad.png',
    'angry':    'emojis/angry.png',
    'surprise': 'emojis/surprise.png',
    'fear':     'emojis/fear.png',
    'disgust':  'emojis/disgust.png',
    'neutral':  'emojis/neutral.png',
}


def overlay_png(bg, fg, x, y):
    """
    íˆ¬ëª… PNG(fg, BGRA)ë¥¼ ë°°ê²½(bg, BGR)ì— í•©ì„±
    (x, y): ë°°ì¹˜í•  ì¢Œìƒë‹¨ ì¢Œí‘œ
    """
    H, W = bg.shape[:2]
    Hf, Wf = fg.shape[:2]
    if x >= W or y >= H:
        return bg

    x1, y1 = max(0, x), max(0, y)
    x2, y2 = min(W, x + Wf), min(H, y + Hf)

    fg_x1, fg_y1 = x1 - x, y1 - y
    fg_x2, fg_y2 = fg_x1 + (x2 - x1), fg_y1 + (y2 - y1)

    if x1 >= x2 or y1 >= y2:
        return bg

    roi = bg[y1:y2, x1:x2]
    fg_crop = fg[fg_y1:fg_y2, fg_x1:fg_x2]

    if fg_crop.shape[2] == 4:
        alpha = fg_crop[:, :, 3:4] / 255.0
        fg_rgb = fg_crop[:, :, :3]
        blended = (alpha * fg_rgb + (1.0 - alpha) * roi).astype(np.uint8)
        bg[y1:y2, x1:x2] = blended
    else:
        # ì•ŒíŒŒê°€ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ë®ì–´ì”€
        bg[y1:y2, x1:x2] = fg_crop[:, :, :3]

    return bg


def add_emotion_emojis(image_path, emotions, out_path='with_emoji.png',
                       emoji_map=EMOJI_MAP, size_scale=0.6, y_offset_ratio=0.15):
    """
    ë¶„ì„ ê²°ê³¼(emotions)ì— ë”°ë¼ ì–¼êµ´ ì£¼ë³€ì— ê°ì • ì´ëª¨ì§€ë¥¼ ì˜¤ë²„ë ˆì´í•˜ì—¬ ì €ì¥
    emotions: [{'emotion': 'happy', 'confidence': 99.0, 'box': (x,y,w,h)}, ...]
    """
    img = cv2.imread(image_path)
    if img is None:
        raise FileNotFoundError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")

    emoji_cache = {}
    for e in emotions:
        emotion = e.get('emotion')
        x, y, w, h = e.get('box', (None, None, None, None))
        if emotion not in emoji_map or None in (x, y, w, h):
            continue

        if emotion not in emoji_cache:
            p = emoji_map[emotion]
            if not os.path.exists(p):
                continue
            png = cv2.imread(p, cv2.IMREAD_UNCHANGED)  # BGRA
            if png is None:
                continue
            emoji_cache[emotion] = png
        png = emoji_cache[emotion]

        # ì´ëª¨ì§€ í¬ê¸°: ì–¼êµ´ ë†’ì´ì— ë¹„ë¡€
        size = max(24, int(h * size_scale))
        png_resized = cv2.resize(png, (size, size), interpolation=cv2.INTER_AREA)

        # ì–¼êµ´ ìƒë‹¨ ì¤‘ì•™ì— ì‚´ì§ ë„ì›Œ ë°°ì¹˜
        y_off = int(h * y_offset_ratio)
        place_x = int(x + w / 2 - size / 2)
        place_y = int(y - size - y_off)

        img = overlay_png(img, png_resized, place_x, place_y)

    cv2.imwrite(out_path, img)
    return out_path


class EmotionAnalyzer:
    def __init__(self):
        self.emotions = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']
        self.emotion_korean = {
            'angry': 'í™”ë‚¨', 'disgust': 'ì—­ê²¨ì›€', 'fear': 'ë‘ë ¤ì›€',
            'happy': 'í–‰ë³µ', 'sad': 'ìŠ¬í””', 'surprise': 'ë†€ëŒ', 'neutral': 'ë¬´í‘œì •'
        }

    def analyze_emotion(self, image_path):
        try:
            result = DeepFace.analyze(image_path, actions=['emotion'], enforce_detection=False)
            # DeepFace ë²„ì „ì— ë”°ë¼ ë‹¨ì¼/ë³µìˆ˜ í¬ë§· ë‹¤ë¦„
            faces = result if isinstance(result, list) else [result]
            out = []
            for face in faces:
                emotion = face['dominant_emotion']
                conf = float(face['emotion'][emotion])
                region = face.get('region', {}) or {}
                x, y, w, h = region.get('x'), region.get('y'), region.get('w'), region.get('h')
                out.append({'emotion': emotion, 'confidence': conf, 'box': (x, y, w, h)})
            return out
        except Exception as e:
            print(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []

    def analyze_multiple_images(self, image_paths):
        results = {}
        for p in image_paths:
            if os.path.exists(p):
                print(f"ë¶„ì„ ì¤‘: {p}")
                results[p] = self.analyze_emotion(p)
            else:
                print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {p}")
                results[p] = []
        return results

    def visualize_results(self, results, save_path=None, show_plot=True):
        if not results:
            print("ì‹œê°í™”í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."); return
        n = len(results)
        fig, axes = plt.subplots(n, 2, figsize=(20, 8 * n))
        if n == 1:
            axes = np.array([axes])

        for idx, (path, emos) in enumerate(results.items()):
            img_bgr = cv2.imread(path)
            if img_bgr is None:
                axes[idx, 0].text(0.5, 0.5, f"ì´ë¯¸ì§€ë¥¼ ì—´ ìˆ˜ ì—†ìŒ\n{os.path.basename(path)}",
                                  ha='center', va='center', transform=axes[idx, 0].transAxes)
                axes[idx, 0].axis('off')
            else:
                img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                for i, e in enumerate(emos or []):
                    x, y, w, h = e.get('box', (None, None, None, None))
                    if None not in (x, y, w, h):
                        cv2.rectangle(img_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)
                        cv2.putText(img_rgb, f"{i+1}:{e['emotion']}", (x, y - 8),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
                axes[idx, 0].imshow(img_rgb); axes[idx, 0].axis('off')

            axes[idx, 1].axis('off')
            txt = "result:\n\n" + "\n".join(
                [f"face {i+1}: {e['emotion']} ({e['confidence']:.1f}%)" for i, e in enumerate(emos or [])]
            ) if emos else "ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            axes[idx, 1].text(0.1, 0.9, txt, transform=axes[idx, 1].transAxes,
                              fontsize=12, va='top',
                              bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue' if emos else 'lightcoral', alpha=0.85))

        plt.tight_layout()
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ì‹œê°í™” ê²°ê³¼ ì €ì¥: {save_path}")
        if show_plot:
            plt.show()
        else:
            plt.close(fig)

    def print_summary(self, results):
        print("\n" + "=" * 50)
        print("ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        total = 0
        cnt = {e: 0 for e in self.emotions}
        for p, emos in results.items():
            print(f"\nğŸ“¸ {os.path.basename(p)}:")
            if emos:
                for i, e in enumerate(emos):
                    print(f"  ì–¼êµ´ {i+1}: {e['emotion']} ({e['confidence']:.1f}%)")
                    cnt[e['emotion']] += 1; total += 1
            else:
                print("  âŒ ì–¼êµ´ì„ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"\nğŸ“Š ì´ ì–¼êµ´ ìˆ˜: {total}")
        if total:
            print("  ê°ì • ë¶„í¬:")
            for k, v in cnt.items():
                if v:
                    print(f"    {k}: {v}ëª… ({100*v/total:.1f}%)")


def main():
    analyzer = EmotionAnalyzer()

    test_images = ['input.jpg']
    existing = [p for p in test_images if os.path.exists(p)]
    if not existing:
        print("ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        sample = np.random.randint(0, 255, (300, 400, 3), dtype=np.uint8)
        cv2.imwrite('sample_face.jpg', sample)
        existing = ['sample_face.jpg']

    print(f"ë¶„ì„í•  ì´ë¯¸ì§€: {existing}")
    results = analyzer.analyze_multiple_images(existing)

    # 1) íŒ¨ë„ ì‹œê°í™” ì €ì¥
    analyzer.visualize_results(results, save_path="emotion_result.png", show_plot=False)

    # 2) ì–¼êµ´ ì£¼ë³€ì— ê°ì • ì´ëª¨ì§€ ì˜¤ë²„ë ˆì´ ì €ì¥
    for img_path, emos in results.items():
        out_path = os.path.splitext(os.path.basename(img_path))[0] + "_emoji.png"
        saved = add_emotion_emojis(img_path, emos, out_path=out_path)
        print(f"ì´ëª¨ì§€ ì˜¤ë²„ë ˆì´ ì €ì¥: {saved}")

    analyzer.print_summary(results)


if __name__ == "__main__":
    main()